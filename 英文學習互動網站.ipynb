{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGrLuS/NZ2cQLipzTLR4A3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kettn0504/teacher-irv-site/blob/main/%E8%8B%B1%E6%96%87%E5%AD%B8%E7%BF%92%E4%BA%92%E5%8B%95%E7%B6%B2%E7%AB%99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£å»ºç«‹ API ä¼ºæœå™¨éœ€è¦çš„å¥—ä»¶\n",
        "!pip install fastapi uvicorn nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuGYs1KD36gB",
        "outputId": "4d1475eb-d653-450b-ab34-d871525f2dfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "import random\n",
        "import re\n",
        "\n",
        "# è®“ Colab å¯ä»¥åŸ·è¡ŒéåŒæ­¥ä¼ºæœå™¨\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- è³‡æ–™æ¨¡å‹ (å°æ‡‰å‰ç«¯ Tiptap JSON) ---\n",
        "class VariableAttrs(BaseModel):\n",
        "    type: str\n",
        "    rule: str\n",
        "    originalText: str\n",
        "\n",
        "class TiptapNode(BaseModel):\n",
        "    type: str\n",
        "    text: Optional[str] = None\n",
        "    attrs: Optional[VariableAttrs] = None\n",
        "\n",
        "class PreviewRequest(BaseModel):\n",
        "    content: List[TiptapNode]\n",
        "\n",
        "# --- æ¨¡æ“¬è³‡æ–™åº« (Mock Vocabulary) ---\n",
        "MOCK_VOCAB = {\n",
        "    \"verb\": {\n",
        "        \"past\": [\"played\", \"ate\", \"studied\", \"wrote\", \"visited\"],\n",
        "        \"base\": [\"play\", \"eat\", \"study\", \"write\", \"visit\"],\n",
        "        \"pp\": [\"played\", \"eaten\", \"studied\", \"written\", \"visited\"]\n",
        "    },\n",
        "    \"noun\": {\n",
        "        \"singular\": [\"piano\", \"apple\", \"book\", \"letter\", \"museum\"],\n",
        "        \"plural\": [\"pianos\", \"apples\", \"books\", \"letters\", \"museums\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- æ ¸å¿ƒé‚è¼¯ (The Brain) ---\n",
        "def generate_sentence_from_template(template_str: str) -> str:\n",
        "    # æ›¿æ›é‚è¼¯ï¼šæ‰¾åˆ° {verb:past} é€™ç¨®æ¨™ç±¤ä¸¦å»æŸ¥è¡¨\n",
        "    def replacer(match):\n",
        "        key = match.group(1) # e.g., \"verb:past\"\n",
        "        try:\n",
        "            pos, form = key.split(\":\")\n",
        "            if pos in MOCK_VOCAB and form in MOCK_VOCAB[pos]:\n",
        "                return random.choice(MOCK_VOCAB[pos][form])\n",
        "            return f\"[{key}?]\" # æŸ¥ç„¡æ­¤å­—\n",
        "        except:\n",
        "            return key\n",
        "\n",
        "    return re.sub(r\"\\{(.*?)\\}\", replacer, template_str)\n",
        "\n",
        "def parse_tiptap_to_template(nodes: List[TiptapNode]) -> str:\n",
        "    # æŠŠ JSON ç‰©ä»¶è½‰å›å­—ä¸²æ¨¡æ¿\n",
        "    parts = []\n",
        "    for node in nodes:\n",
        "        if node.type == \"text\":\n",
        "            parts.append(node.text)\n",
        "        elif node.type == \"variableBlock\":\n",
        "            tag = f\"{{{node.attrs.type}:{node.attrs.rule}}}\"\n",
        "            parts.append(tag)\n",
        "    return \"\".join(parts)\n",
        "\n",
        "# --- API æ¥å£ ---\n",
        "@app.post(\"/api/preview-template\")\n",
        "async def preview_template(request: PreviewRequest):\n",
        "    raw_template = parse_tiptap_to_template(request.content)\n",
        "    # ç”Ÿæˆ 5 å€‹éš¨æ©Ÿçµæœ\n",
        "    results = [generate_sentence_from_template(raw_template) for _ in range(5)]\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"parsed_template\": raw_template,\n",
        "        \"generated_sentences\": results\n",
        "    }\n",
        "\n",
        "# --- åœ¨èƒŒæ™¯å•Ÿå‹•ä¼ºæœå™¨ ---\n",
        "def run_server():\n",
        "    print(\"ğŸš€ ä¼ºæœå™¨æ­£åœ¨èƒŒæ™¯å•Ÿå‹•ä¸­...\")\n",
        "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"warning\")\n",
        "\n",
        "thread = threading.Thread(target=run_server)\n",
        "thread.start()\n",
        "print(\"âœ… ä¼ºæœå™¨å·²å°±ç·’ï¼å¯ä»¥é–‹å§‹æ¸¬è©¦ API äº†ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDcvTFUl4DsP",
        "outputId": "c0936fa2-ff7b-4e6a-f642-e3d9601ec16e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ä¼ºæœå™¨æ­£åœ¨èƒŒæ™¯å•Ÿå‹•ä¸­...âœ… ä¼ºæœå™¨å·²å°±ç·’ï¼å¯ä»¥é–‹å§‹æ¸¬è©¦ API äº†ã€‚\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ç¢ºä¿ä¼ºæœå™¨å·²ç¶“å®Œå…¨å•Ÿå‹•\n",
        "time.sleep(1)\n",
        "\n",
        "print(\"æ­£åœ¨å‚³é€æ¸¬è©¦è³‡æ–™ (æ¨¡æ“¬ä½¿ç”¨è€…è¼¸å…¥: If I [played] the [piano]...)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# é€™æ˜¯æ¨¡æ“¬å‰ç«¯ (React/Tiptap) å‚³éä¾†çš„ JSON\n",
        "payload = {\n",
        "    \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"If I \"},\n",
        "        # é€™è£¡æ¨¡æ“¬ä½¿ç”¨è€…æŠŠ \"played\" è®Šæˆäº†è®Šæ•¸\n",
        "        {\n",
        "            \"type\": \"variableBlock\",\n",
        "            \"attrs\": {\"type\": \"verb\", \"rule\": \"past\", \"originalText\": \"played\"}\n",
        "        },\n",
        "        {\"type\": \"text\", \"text\": \" the \"},\n",
        "        # é€™è£¡æ¨¡æ“¬ä½¿ç”¨è€…æŠŠ \"piano\" è®Šæˆäº†è®Šæ•¸\n",
        "        {\n",
        "            \"type\": \"variableBlock\",\n",
        "            \"attrs\": {\"type\": \"noun\", \"rule\": \"singular\", \"originalText\": \"piano\"}\n",
        "        },\n",
        "        {\"type\": \"text\", \"text\": \".\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "try:\n",
        "    # ç™¼é€ POST è«‹æ±‚çµ¦æœ¬åœ°ä¼ºæœå™¨\n",
        "    response = requests.post(\"http://127.0.0.1:8000/api/preview-template\", json=payload)\n",
        "    data = response.json()\n",
        "\n",
        "    # é¡¯ç¤ºçµæœ\n",
        "    print(f\"è§£æå¾Œçš„æ¨¡æ¿é‚è¼¯: {data['parsed_template']}\")\n",
        "    print(\"\\nâœ¨ ç”Ÿæˆçš„éš¨æ©Ÿé¡Œç›® (Random Output):\")\n",
        "    for idx, sentence in enumerate(data['generated_sentences'], 1):\n",
        "        print(f\"{idx}. {sentence}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ç™¼ç”ŸéŒ¯èª¤: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF_T806S4IfU",
        "outputId": "dbe49e4f-7d99-4692-bebf-6cd2d39788b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨å‚³é€æ¸¬è©¦è³‡æ–™ (æ¨¡æ“¬ä½¿ç”¨è€…è¼¸å…¥: If I [played] the [piano]...)\n",
            "--------------------------------------------------\n",
            "è§£æå¾Œçš„æ¨¡æ¿é‚è¼¯: If I {verb:past} the {noun:singular}.\n",
            "\n",
            "âœ¨ ç”Ÿæˆçš„éš¨æ©Ÿé¡Œç›® (Random Output):\n",
            "1. If I wrote the apple.\n",
            "2. If I visited the book.\n",
            "3. If I studied the book.\n",
            "4. If I visited the book.\n",
            "5. If I played the museum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# å‡ç´šç‰ˆï¼šåŠ å…¥èªæ„æ¨™ç±¤ (Semantic Tags)\n",
        "# ==========================================\n",
        "\n",
        "# 1. è³‡æ–™åº«æ“´å……ï¼šåŠ å…¥ tags æ¬„ä½\n",
        "MOCK_VOCAB_V2 = {\n",
        "    \"verb\": [\n",
        "        # é£Ÿç‰©é¡å‹•è©\n",
        "        {\"base\": \"eat\", \"past\": \"ate\", \"tags\": [\"food_action\"]},\n",
        "        {\"base\": \"cook\", \"past\": \"cooked\", \"tags\": [\"food_action\"]},\n",
        "        # éŸ³æ¨‚é¡å‹•è©\n",
        "        {\"base\": \"play\", \"past\": \"played\", \"tags\": [\"music_action\"]},\n",
        "        {\"base\": \"listen to\", \"past\": \"listened to\", \"tags\": [\"music_action\"]},\n",
        "        # é–±è®€é¡å‹•è©\n",
        "        {\"base\": \"read\", \"past\": \"read\", \"tags\": [\"text_action\"]},\n",
        "        {\"base\": \"write\", \"past\": \"wrote\", \"tags\": [\"text_action\"]},\n",
        "    ],\n",
        "    \"noun\": [\n",
        "        # é£Ÿç‰©é¡åè©\n",
        "        {\"singular\": \"apple\", \"tags\": [\"food\"]},\n",
        "        {\"singular\": \"pizza\", \"tags\": [\"food\"]},\n",
        "        {\"singular\": \"steak\", \"tags\": [\"food\"]},\n",
        "        # éŸ³æ¨‚é¡åè©\n",
        "        {\"singular\": \"piano\", \"tags\": [\"instrument\"]},\n",
        "        {\"singular\": \"song\", \"tags\": [\"music\"]},\n",
        "        {\"singular\": \"guitar\", \"tags\": [\"instrument\"]},\n",
        "        # é–±è®€é¡åè©\n",
        "        {\"singular\": \"book\", \"tags\": [\"text\"]},\n",
        "        {\"singular\": \"letter\", \"tags\": [\"text\"]},\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 2. å®šç¾©é‚è¼¯å°æ‡‰è¦å‰‡ (Mapping)\n",
        "# å‘Šè¨´ç³»çµ±ï¼šå¦‚æœä½ é¸äº† \"food_action\" çš„å‹•è©ï¼Œå—è©æœ€å¥½æ˜¯ \"food\"\n",
        "LOGIC_MAP = {\n",
        "    \"food_action\": [\"food\"],\n",
        "    \"music_action\": [\"instrument\", \"music\"],\n",
        "    \"text_action\": [\"text\"]\n",
        "}\n",
        "\n",
        "# 3. å‡ç´šç‰ˆç”Ÿæˆå™¨\n",
        "def generate_smart_sentence(template_str: str):\n",
        "    # ç”¨ä¾†æš«å­˜ä¸Šä¸€è¼ªé¸åˆ°çš„å‹•è©æ¨™ç±¤ï¼Œä»¥ä¾¿æ±ºå®šåè©è¦é¸ä»€éº¼\n",
        "    context = {\"verb_tag\": None}\n",
        "\n",
        "    def replacer(match):\n",
        "        key = match.group(1) # e.g. \"verb:past\" or \"noun:singular\"\n",
        "        parts = key.split(\":\")\n",
        "        pos, form = parts[0], parts[1]\n",
        "\n",
        "        candidates = []\n",
        "\n",
        "        # --- è™•ç†å‹•è© ---\n",
        "        if pos == \"verb\":\n",
        "            # éš¨æ©Ÿé¸ä¸€å€‹å‹•è©\n",
        "            word_obj = random.choice(MOCK_VOCAB_V2[\"verb\"])\n",
        "            # è¨˜éŒ„é€™å€‹å‹•è©çš„æ¨™ç±¤ (ä¾‹å¦‚ food_action)ï¼Œçµ¦ä¸‹ä¸€å€‹åè©åƒè€ƒ\n",
        "            context[\"verb_tag\"] = word_obj[\"tags\"][0]\n",
        "            return word_obj[form]\n",
        "\n",
        "        # --- è™•ç†åè© ---\n",
        "        elif pos == \"noun\":\n",
        "            # æª¢æŸ¥å‹•è©æ±ºå®šäº†ä»€éº¼æƒ…å¢ƒ\n",
        "            required_tags = LOGIC_MAP.get(context[\"verb_tag\"], [])\n",
        "\n",
        "            # å¾åè©åº«ç¯©é¸ï¼šå¿…é ˆåŒ…å«å°æ‡‰æ¨™ç±¤çš„å­—\n",
        "            # å¦‚æœ required_tags æ˜¯ç©º (æ²’é™åˆ¶)ï¼Œå°±å…¨éƒ¨åè©éƒ½èƒ½é¸\n",
        "            for noun in MOCK_VOCAB_V2[\"noun\"]:\n",
        "                if not required_tags or any(tag in noun[\"tags\"] for tag in required_tags):\n",
        "                    candidates.append(noun)\n",
        "\n",
        "            if candidates:\n",
        "                return random.choice(candidates)[form]\n",
        "            return \"[No Logic Match]\"\n",
        "\n",
        "        return key\n",
        "\n",
        "    return re.sub(r\"\\{(.*?)\\}\", replacer, template_str)\n",
        "\n",
        "# 4. æ¸¬è©¦åŸ·è¡Œ\n",
        "print(\"--- å‡ç´šç‰ˆï¼šæ™ºæ…§èªæ„ç”Ÿæˆ ---\")\n",
        "template = \"If I {verb:past} the {noun:singular}.\"\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"{i+1}. {generate_smart_sentence(template)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnQbLVQN4jJU",
        "outputId": "b9700c83-ce77-4df3-922b-bea4371ab96b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- å‡ç´šç‰ˆï¼šæ™ºæ…§èªæ„ç”Ÿæˆ ---\n",
            "1. If I ate the steak.\n",
            "2. If I cooked the steak.\n",
            "3. If I cooked the steak.\n",
            "4. If I read the book.\n",
            "5. If I cooked the pizza.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. å®‰è£ NLP æ ¸å¿ƒå¥—ä»¶\n",
        "!pip install nltk lemminflect\n",
        "\n",
        "# 2. ä¸‹è¼‰å¿…è¦çš„èªæ–™åº«è³‡æ–™\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # Open Multilingual Wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "print(\"âœ… ç’°å¢ƒå»ºç½®å®Œæˆï¼\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtkl2_EJ5OUh",
        "outputId": "72133ee0-ffa3-49f6-aac3-308a3ae239e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting lemminflect\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lemminflect) (2.0.2)\n",
            "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lemminflect\n",
            "Successfully installed lemminflect-0.2.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç’°å¢ƒå»ºç½®å®Œæˆï¼\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lemminflect\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# --- å·¥äºº A: å‹æ…‹è®ŠåŒ–å°ˆå®¶ ---\n",
        "def get_inflections(word, pos):\n",
        "    \"\"\"\n",
        "    è¼¸å…¥: word='eat', pos='VERB'\n",
        "    è¼¸å‡º: {'past': 'ate', 'pp': 'eaten', ...}\n",
        "    \"\"\"\n",
        "    inflections = {}\n",
        "\n",
        "    if pos == 'VERB':\n",
        "        # å–å¾—éå»å¼ (VBD) å’Œ éå»åˆ†è© (VBN)\n",
        "        inflections['base'] = word\n",
        "        inflections['past'] = lemminflect.getInflection(word, tag='VBD')[0]\n",
        "        inflections['pp'] = lemminflect.getInflection(word, tag='VBN')[0]\n",
        "        inflections['3rd_person'] = lemminflect.getInflection(word, tag='VBZ')[0]\n",
        "        inflections['ing'] = lemminflect.getInflection(word, tag='VBG')[0]\n",
        "\n",
        "    elif pos == 'NOUN':\n",
        "        # å–å¾—è¤‡æ•¸ (NNS)\n",
        "        inflections['singular'] = word\n",
        "        inflections['plural'] = lemminflect.getInflection(word, tag='NNS')[0]\n",
        "\n",
        "    return inflections\n",
        "\n",
        "# --- å·¥äºº B: èªæ„åˆ†é¡å°ˆå®¶ (ä½¿ç”¨ WordNet) ---\n",
        "def get_auto_tags(word, pos):\n",
        "    \"\"\"\n",
        "    è¿½è¹¤å–®å­—çš„ã€Œç¥–å®—åå…«ä»£ã€ï¼Œæ‰¾å‡ºå®ƒæ˜¯ä»€éº¼é¡åˆ¥ã€‚\n",
        "    ä¾‹å¦‚: Apple -> Edible Fruit -> Fruit -> Food ... -> Entity\n",
        "    \"\"\"\n",
        "    tags = set()\n",
        "\n",
        "    # è½‰æ› POS æ ¼å¼çµ¦ WordNet ç”¨ (n=noun, v=verb)\n",
        "    wn_pos = wn.VERB if pos == 'VERB' else wn.NOUN\n",
        "\n",
        "    # å–å¾—è©²å–®å­—çš„ç¬¬ä¸€å€‹å®šç¾© (é€šå¸¸æ˜¯æœ€å¸¸ç”¨çš„æ„æ€)\n",
        "    synsets = wn.synsets(word, pos=wn_pos)\n",
        "    if not synsets:\n",
        "        return list(tags)\n",
        "\n",
        "    synset = synsets[0] # å–ç¬¬ä¸€å€‹ç¾©é …\n",
        "\n",
        "    # --- å®šç¾©æˆ‘å€‘æ„Ÿèˆˆè¶£çš„ã€Œä¸Šä½è© (Hypernyms)ã€ ---\n",
        "    # é€™äº›æ˜¯æˆ‘å€‘æƒ³è‡ªå‹•æ¨™è¨˜çš„åˆ†é¡\n",
        "    target_categories = {\n",
        "        \"food\": [\"food\", \"meal\", \"nutrient\"],\n",
        "        \"animal\": [\"animal\", \"creature\"],\n",
        "        \"place\": [\"location\", \"area\", \"structure\", \"building\"],\n",
        "        \"music\": [\"music\", \"instrument\"],\n",
        "        \"movement\": [\"travel\", \"move\", \"motion\"]\n",
        "    }\n",
        "\n",
        "    # éè¿´å°‹æ‰¾é€™å€‹å­—çš„æ‰€æœ‰ä¸Šä½è©\n",
        "    # hypernym_paths() æœƒå›å‚³é€™å€‹å­—åˆ°æ ¹ç¯€é»çš„æ‰€æœ‰è·¯å¾‘\n",
        "    for path in synset.hypernym_paths():\n",
        "        for node in path:\n",
        "            node_name = node.name().split('.')[0] # e.g., 'food.n.02' -> 'food'\n",
        "\n",
        "            # æª¢æŸ¥é€™å€‹ç¯€é»æ˜¯å¦åœ¨æˆ‘å€‘çš„ç›®æ¨™åˆ†é¡ä¸­\n",
        "            for tag, keywords in target_categories.items():\n",
        "                if node_name in keywords:\n",
        "                    tags.add(tag)\n",
        "\n",
        "    return list(tags)\n",
        "\n",
        "# --- ä¸»ç”¢ç·š: æ‰¹é‡ç”Ÿç”¢ ---\n",
        "def process_vocabulary_list(raw_list):\n",
        "    processed_data = []\n",
        "\n",
        "    print(f\"ğŸ­ é–‹å§‹åŠ å·¥ {len(raw_list)} å€‹å–®å­—...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for item in raw_list:\n",
        "        word = item[\"word\"]\n",
        "        pos = item[\"pos\"] # 'VERB' or 'NOUN'\n",
        "\n",
        "        # 1. å–å¾—è®ŠåŒ–å½¢\n",
        "        inflections = get_inflections(word, pos)\n",
        "\n",
        "        # 2. è‡ªå‹•åˆ¤æ–·æ¨™ç±¤\n",
        "        tags = get_auto_tags(word, pos)\n",
        "\n",
        "        # 3. çµ„è£æˆè³‡æ–™åº«æ ¼å¼\n",
        "        entry = {\n",
        "            \"base_word\": word,\n",
        "            \"pos\": pos.lower(),\n",
        "            \"inflections\": inflections,\n",
        "            \"tags\": tags,\n",
        "            \"definition\": wn.synsets(word)[0].definition() if wn.synsets(word) else \"\"\n",
        "        }\n",
        "        processed_data.append(entry)\n",
        "\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "0hmgSbsE5UX6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é€™æ˜¯ä½ æº–å‚™åŒ¯å…¥çš„ã€Œç¨®å­æ¸…å–®ã€ (åªè¦çµ¦åŸå‹å°±å¥½)\n",
        "seed_vocabulary = [\n",
        "    {\"word\": \"eat\", \"pos\": \"VERB\"},\n",
        "    {\"word\": \"fly\", \"pos\": \"VERB\"},\n",
        "    {\"word\": \"piano\", \"pos\": \"NOUN\"},\n",
        "    {\"word\": \"banana\", \"pos\": \"NOUN\"},\n",
        "    {\"word\": \"dog\", \"pos\": \"NOUN\"},\n",
        "    {\"word\": \"library\", \"pos\": \"NOUN\"},\n",
        "    {\"word\": \"drive\", \"pos\": \"VERB\"}\n",
        "]\n",
        "\n",
        "# å•Ÿå‹•ç”Ÿç”¢ç·š\n",
        "final_database = process_vocabulary_list(seed_vocabulary)\n",
        "\n",
        "# é¡¯ç¤ºçµæœ\n",
        "import json\n",
        "print(json.dumps(final_database, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_l1vTU95Zl1",
        "outputId": "29cafd38-4711-4210-c1b9-0c5fa240491c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ­ é–‹å§‹åŠ å·¥ 7 å€‹å–®å­—...\n",
            "----------------------------------------\n",
            "[\n",
            "  {\n",
            "    \"base_word\": \"eat\",\n",
            "    \"pos\": \"verb\",\n",
            "    \"inflections\": {\n",
            "      \"base\": \"eat\",\n",
            "      \"past\": \"ate\",\n",
            "      \"pp\": \"eaten\",\n",
            "      \"3rd_person\": \"eats\",\n",
            "      \"ing\": \"eating\"\n",
            "    },\n",
            "    \"tags\": [],\n",
            "    \"definition\": \"take in solid food\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"fly\",\n",
            "    \"pos\": \"verb\",\n",
            "    \"inflections\": {\n",
            "      \"base\": \"fly\",\n",
            "      \"past\": \"flew\",\n",
            "      \"pp\": \"flown\",\n",
            "      \"3rd_person\": \"flies\",\n",
            "      \"ing\": \"flying\"\n",
            "    },\n",
            "    \"tags\": [\n",
            "      \"movement\"\n",
            "    ],\n",
            "    \"definition\": \"two-winged insects characterized by active flight\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"piano\",\n",
            "    \"pos\": \"noun\",\n",
            "    \"inflections\": {\n",
            "      \"singular\": \"piano\",\n",
            "      \"plural\": \"pianos\"\n",
            "    },\n",
            "    \"tags\": [],\n",
            "    \"definition\": \"a keyboard instrument that is played by depressing keys that cause hammers to strike tuned strings and produce sounds\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"banana\",\n",
            "    \"pos\": \"noun\",\n",
            "    \"inflections\": {\n",
            "      \"singular\": \"banana\",\n",
            "      \"plural\": \"bananas\"\n",
            "    },\n",
            "    \"tags\": [],\n",
            "    \"definition\": \"any of several tropical and subtropical treelike herbs of the genus Musa having a terminal crown of large entire leaves and usually bearing hanging clusters of elongated fruits\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"dog\",\n",
            "    \"pos\": \"noun\",\n",
            "    \"inflections\": {\n",
            "      \"singular\": \"dog\",\n",
            "      \"plural\": \"dogs\"\n",
            "    },\n",
            "    \"tags\": [\n",
            "      \"animal\"\n",
            "    ],\n",
            "    \"definition\": \"a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"library\",\n",
            "    \"pos\": \"noun\",\n",
            "    \"inflections\": {\n",
            "      \"singular\": \"library\",\n",
            "      \"plural\": \"libraries\"\n",
            "    },\n",
            "    \"tags\": [\n",
            "      \"place\"\n",
            "    ],\n",
            "    \"definition\": \"a room where books are kept\"\n",
            "  },\n",
            "  {\n",
            "    \"base_word\": \"drive\",\n",
            "    \"pos\": \"verb\",\n",
            "    \"inflections\": {\n",
            "      \"base\": \"drive\",\n",
            "      \"past\": \"drove\",\n",
            "      \"pp\": \"driven\",\n",
            "      \"3rd_person\": \"drives\",\n",
            "      \"ing\": \"driving\"\n",
            "    },\n",
            "    \"tags\": [],\n",
            "    \"definition\": \"the act of applying force to propel something\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "import lemminflect\n",
        "\n",
        "# ==========================================\n",
        "# 1. å®šç¾©ä¸»è©åº« (Leaders)\n",
        "# å¿…é ˆåŒ…å«äººç¨± (person) èˆ‡å–®è¤‡æ•¸ (number)\n",
        "# ==========================================\n",
        "SUBJECTS = [\n",
        "    # ç¬¬ä¸€äººç¨±\n",
        "    {\"word\": \"I\", \"person\": 1, \"number\": \"singular\", \"tags\": [\"human\"]},\n",
        "    {\"word\": \"We\", \"person\": 1, \"number\": \"plural\", \"tags\": [\"human\"]},\n",
        "    # ç¬¬äºŒäººç¨±\n",
        "    {\"word\": \"You\", \"person\": 2, \"number\": \"plural\", \"tags\": [\"human\"]}, # You è¦–ç‚ºè¤‡æ•¸å‹æ…‹è™•ç†\n",
        "    # ç¬¬ä¸‰äººç¨±å–®æ•¸\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"tags\": [\"human\"]},\n",
        "    {\"word\": \"She\", \"person\": 3, \"number\": \"singular\", \"tags\": [\"human\"]},\n",
        "    {\"word\": \"The doctor\", \"person\": 3, \"number\": \"singular\", \"tags\": [\"human\", \"job\"]},\n",
        "    {\"word\": \"The dog\", \"person\": 3, \"number\": \"singular\", \"tags\": [\"animal\"]},\n",
        "    # ç¬¬ä¸‰äººç¨±è¤‡æ•¸\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"tags\": [\"human\"]},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"tags\": [\"human\"]},\n",
        "]\n",
        "\n",
        "# ==========================================\n",
        "# 2. å®šç¾©å‹•è©åº« (Followers)\n",
        "# ==========================================\n",
        "VERBS = [\n",
        "    {\"base\": \"eat\", \"tags\": [\"food_action\"]},\n",
        "    {\"base\": \"play\", \"tags\": [\"game_action\", \"music_action\"]},\n",
        "    {\"base\": \"study\", \"tags\": [\"study_action\"]},\n",
        "    {\"base\": \"teach\", \"tags\": [\"study_action\"]},\n",
        "    {\"base\": \"watch\", \"tags\": [\"visual_action\"]},\n",
        "    {\"base\": \"be\", \"tags\": [\"state\"]}, # Be å‹•è©æ˜¯é­”ç‹ï¼Œè¦ç‰¹åˆ¥è™•ç†\n",
        "]\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ–‡æ³•è­¦å¯Ÿæ ¸å¿ƒ (Grammar Logic)\n",
        "# ==========================================\n",
        "def conjugate_verb(verb_base, subject_props, tense):\n",
        "    \"\"\"\n",
        "    æ ¹æ“šä¸»è©å±¬æ€§å’Œæ™‚æ…‹ï¼Œæ±ºå®šå‹•è©çš„æ­£ç¢ºè®ŠåŒ–\n",
        "    \"\"\"\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "\n",
        "    # --- è™•ç† BE å‹•è© (æœ€éº»ç…©çš„ç‰¹ä¾‹) ---\n",
        "    if verb_base == \"be\":\n",
        "        if tense == \"past\":\n",
        "            # éå»å¼: was (1st, 3rd sg) / were (others)\n",
        "            if number == \"singular\" and person in [1, 3]:\n",
        "                return \"was\"\n",
        "            return \"were\"\n",
        "        else: # present\n",
        "            # ç¾åœ¨å¼: am, is, are\n",
        "            if person == 1 and number == \"singular\": return \"am\"\n",
        "            if person == 3 and number == \"singular\": return \"is\"\n",
        "            return \"are\"\n",
        "\n",
        "    # --- è™•ç†ä¸€èˆ¬å‹•è© ---\n",
        "    if tense == \"past\":\n",
        "        # éå»å¼æœ€ç°¡å–®ï¼Œå¤§å®¶éƒ½ä¸€æ¨£ (VBD)\n",
        "        return lemminflect.getInflection(verb_base, tag='VBD')[0]\n",
        "\n",
        "    elif tense == \"present\":\n",
        "        # ç¾åœ¨å¼é—œéµåˆ¤æ–·ï¼šæ˜¯ä¸æ˜¯ç¬¬ä¸‰äººç¨±å–®æ•¸ (3rd + Singular)?\n",
        "        if person == 3 and number == \"singular\":\n",
        "            # æ˜¯ -> ç”¨ VBZ (eats, goes)\n",
        "            return lemminflect.getInflection(verb_base, tag='VBZ')[0]\n",
        "        else:\n",
        "            # å¦ -> ç”¨ VBP (eat, go)\n",
        "            return lemminflect.getInflection(verb_base, tag='VBP')[0]\n",
        "\n",
        "    return verb_base\n",
        "\n",
        "# ==========================================\n",
        "# 4. å…·å‚™æ–‡æ³•æ„è­˜çš„ç”Ÿæˆå™¨\n",
        "# ==========================================\n",
        "def generate_grammatically_correct_sentence(template_str):\n",
        "    # ç”¨ä¾†è¨˜ä½é€™ä¸€å¥è©±çš„ä¸»è©æ˜¯èª°\n",
        "    context = {\"subject\": None}\n",
        "\n",
        "    def replacer(match):\n",
        "        key = match.group(1) # e.g. \"subj\" or \"verb:present\"\n",
        "\n",
        "        # --- è™•ç†ä¸»è© (Subject) ---\n",
        "        if key.startswith(\"subj\"):\n",
        "            # éš¨æ©Ÿé¸ä¸€å€‹ä¸»è©\n",
        "            subj_obj = random.choice(SUBJECTS)\n",
        "            # å­˜å…¥ contextï¼Œè®“å¾Œé¢çš„å‹•è©å¯ä»¥åƒè€ƒ\n",
        "            context[\"subject\"] = subj_obj\n",
        "            return subj_obj[\"word\"]\n",
        "\n",
        "        # --- è™•ç†å‹•è© (Verb) ---\n",
        "        elif key.startswith(\"verb\"):\n",
        "            parts = key.split(\":\") # [\"verb\", \"present\", \"food_action\"(opt)]\n",
        "            tense = parts[1] # present or past\n",
        "\n",
        "            # 1. ç¢ºä¿å‰é¢å·²ç¶“æœ‰ç”Ÿæˆä¸»è©äº†\n",
        "            if context[\"subject\"] is None:\n",
        "                return \"[Error: Verb before Subject]\"\n",
        "\n",
        "            # 2. éš¨æ©Ÿé¸ä¸€å€‹å‹•è© (é€™è£¡çœç•¥äº† Tag éæ¿¾ï¼Œå…ˆå°ˆæ³¨æ–‡æ³•)\n",
        "            verb_obj = random.choice(VERBS)\n",
        "\n",
        "            # 3. *** å‘¼å«æ–‡æ³•è­¦å¯Ÿé€²è¡Œè®Šå½¢ ***\n",
        "            final_verb = conjugate_verb(verb_obj[\"base\"], context[\"subject\"], tense)\n",
        "\n",
        "            return final_verb\n",
        "\n",
        "        return key\n",
        "\n",
        "    return re.sub(r\"\\{(.*?)\\}\", replacer, template_str)\n",
        "\n",
        "# ==========================================\n",
        "# 5. é©—è­‰æ™‚åˆ» (Moment of Truth)\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- æ¸¬è©¦ç¾åœ¨å¼ä¸€è‡´æ€§ (Present Tense Agreement) ---\")\n",
        "template_present = \"{subj} {verb:present} English.\"\n",
        "\n",
        "for _ in range(5):\n",
        "    print(generate_grammatically_correct_sentence(template_present))\n",
        "\n",
        "print(\"\\n--- æ¸¬è©¦ BE å‹•è©éå»å¼ (Past Tense 'Be') ---\")\n",
        "# æˆ‘å€‘å¼·åˆ¶è®“å‹•è©è®Šæˆ be æ¸¬è©¦çœ‹çœ‹\n",
        "def test_be_sentence():\n",
        "    subj = random.choice(SUBJECTS)\n",
        "    verb = conjugate_verb(\"be\", subj, \"past\")\n",
        "    return f\"{subj['word']} {verb} happy.\"\n",
        "\n",
        "for _ in range(5):\n",
        "    print(test_be_sentence())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShTFZ526S5k",
        "outputId": "2dc3e637-69de-44eb-99b9-396beb50239b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- æ¸¬è©¦ç¾åœ¨å¼ä¸€è‡´æ€§ (Present Tense Agreement) ---\n",
            "The students teach English.\n",
            "You eat English.\n",
            "We are English.\n",
            "The doctor watches English.\n",
            "We eat English.\n",
            "\n",
            "--- æ¸¬è©¦ BE å‹•è©éå»å¼ (Past Tense 'Be') ---\n",
            "We were happy.\n",
            "He was happy.\n",
            "The doctor was happy.\n",
            "He was happy.\n",
            "The students were happy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import lemminflect\n",
        "\n",
        "# ==========================================\n",
        "# 1. è³‡æ–™åº«æº–å‚™\n",
        "# ==========================================\n",
        "\n",
        "# ä¸»è©åº« (åŸæœ¬çš„å‹•ä½œåŸ·è¡Œè€…)\n",
        "AGENTS = [\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    {\"word\": \"I\", \"person\": 1, \"number\": \"singular\", \"type\": \"pronoun\"}, # ä»£åè©éœ€è¦è®Šæ ¼ (I -> me)\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"}, # ä»£åè©éœ€è¦è®Šæ ¼ (He -> him)\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"type\": \"pronoun\"}\n",
        "]\n",
        "\n",
        "# åŠç‰©å‹•è©åº« (åªæœ‰åŠç‰©å‹•è©æ‰æœ‰è¢«å‹•èªæ…‹ï¼)\n",
        "# æˆ‘å€‘éœ€è¦ Vpp (éå»åˆ†è©)\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\"},\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\"},\n",
        "    {\"base\": \"clean\", \"vpp\": \"cleaned\"},\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\"},\n",
        "    {\"base\": \"love\", \"vpp\": \"loved\"},\n",
        "]\n",
        "\n",
        "# å—è©åº« (åŸæœ¬çš„æ¥å—è€…ï¼Œå°‡è®Šæˆæ–°ä¸»è©)\n",
        "TARGETS = [\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\"},\n",
        "    {\"word\": \"the apple\", \"person\": 3, \"number\": \"singular\"},\n",
        "    {\"word\": \"the cookies\", \"person\": 3, \"number\": \"plural\"},\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\"},\n",
        "]\n",
        "\n",
        "# ä»£åè©å—æ ¼å°ç…§è¡¨ (Subject -> Object)\n",
        "PRONOUN_OBJ_MAP = {\n",
        "    \"I\": \"me\",\n",
        "    \"He\": \"him\",\n",
        "    \"She\": \"her\",\n",
        "    \"We\": \"us\",\n",
        "    \"They\": \"them\",\n",
        "    \"You\": \"you\"\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. è¼”åŠ©å‡½å¼ï¼šBe å‹•è©è®ŠåŒ–è¨ˆç®—æ©Ÿ\n",
        "# ==========================================\n",
        "def get_be_verb(subject_props, tense):\n",
        "    \"\"\"\n",
        "    è¢«å‹•èªæ…‹çš„æ ¸å¿ƒï¼šBe å‹•è©å¿…é ˆè·Ÿè‘—ã€Œæ–°ä¸»è©ã€è®Š\n",
        "    \"\"\"\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "\n",
        "    if tense == \"past\":\n",
        "        # Past: was / were\n",
        "        if number == \"singular\" and person in [1, 3]:\n",
        "            return \"was\"\n",
        "        return \"were\"\n",
        "    elif tense == \"present\":\n",
        "        # Present: am / is / are\n",
        "        if person == 1 and number == \"singular\": return \"am\"\n",
        "        if person == 3 and number == \"singular\": return \"is\"\n",
        "        return \"are\"\n",
        "    elif tense == \"future\":\n",
        "        return \"will be\"\n",
        "\n",
        "    return \"is\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ ¸å¿ƒé‚è¼¯ï¼šè¢«å‹•èªæ…‹ç”Ÿæˆå™¨\n",
        "# ==========================================\n",
        "def generate_passive_sentence(tense=\"past\"):\n",
        "    # 1. éš¨æ©ŸæŒ‘é¸ä¸‰å€‹å…ƒç´ \n",
        "    agent = random.choice(AGENTS)         # å…‡æ‰‹ (åŸæœ¬çš„ä¸»è©)\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS) # å‹•ä½œ\n",
        "    target = random.choice(TARGETS)       # å—å®³è€… (åŸæœ¬çš„å—è© -> æ–°ä¸»è©)\n",
        "\n",
        "    # 2. è™•ç† [æ–°ä¸»è©] (The Target)\n",
        "    # å¥å­é–‹é ­è¦å¤§å¯«\n",
        "    new_subject_text = target[\"word\"].capitalize()\n",
        "\n",
        "    # 3. è™•ç† [å‹•è©ç‰‡èª] (Be + Vpp)\n",
        "    # é—œéµï¼šBe å‹•è©è¦é…åˆã€Œæ–°ä¸»è© (Target)ã€ï¼Œè€Œä¸æ˜¯èˆŠä¸»è© (Agent)\n",
        "    be_verb = get_be_verb(target, tense)\n",
        "    main_verb_pp = verb_obj[\"vpp\"] # é€™è£¡å¯ä»¥çµåˆ lemminflect è‡ªå‹•æŸ¥ï¼Œå…ˆç”¨ç¡¬ç·¨ç¢¼ç¤ºç¯„\n",
        "\n",
        "    # 4. è™•ç† [by + Agent]\n",
        "    # å¦‚æœ Agent æ˜¯ä»£åè© (He)ï¼Œè¦è®Šæˆå—æ ¼ (him)\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent.get(\"type\") == \"pronoun\":\n",
        "        agent_text = PRONOUN_OBJ_MAP.get(agent_text, agent_text)\n",
        "\n",
        "    by_phrase = f\"by {agent_text}\"\n",
        "\n",
        "    # 5. çµ„è£\n",
        "    return f\"{new_subject_text} {be_verb} {main_verb_pp} {by_phrase}.\"\n",
        "\n",
        "# ==========================================\n",
        "# 4. é©—è­‰çµæœ\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- éå»è¢«å‹•å¼ (Past Passive) ---\")\n",
        "# çµæ§‹: The apple [was/were] eaten by [him/the teacher].\n",
        "for _ in range(5):\n",
        "    print(generate_passive_sentence(tense=\"past\"))\n",
        "\n",
        "print(\"\\n--- ç¾åœ¨è¢«å‹•å¼ (Present Passive) ---\")\n",
        "# çµæ§‹: The book [is/are] written by [him/the teacher].\n",
        "for _ in range(5):\n",
        "    print(generate_passive_sentence(tense=\"present\"))\n",
        "\n",
        "print(\"\\n--- æœªä¾†è¢«å‹•å¼ (Future Passive) ---\")\n",
        "# çµæ§‹: The book will be written by [him/the teacher].\n",
        "for _ in range(5):\n",
        "    print(generate_passive_sentence(tense=\"future\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLmZQ9f6vBa",
        "outputId": "8706e1ab-3fba-4167-9879-e0c98c38827d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- éå»è¢«å‹•å¼ (Past Passive) ---\n",
            "The cookies were designed by them.\n",
            "The book was eaten by me.\n",
            "The website was eaten by The students.\n",
            "The apple was written by The teacher.\n",
            "The cookies were eaten by The students.\n",
            "\n",
            "--- ç¾åœ¨è¢«å‹•å¼ (Present Passive) ---\n",
            "The letters are written by them.\n",
            "The apple is eaten by The students.\n",
            "The cookies are cleaned by The students.\n",
            "The apple is designed by The students.\n",
            "The book is written by The teacher.\n",
            "\n",
            "--- æœªä¾†è¢«å‹•å¼ (Future Passive) ---\n",
            "The website will be designed by The students.\n",
            "The apple will be cleaned by me.\n",
            "The apple will be cleaned by him.\n",
            "The letters will be eaten by me.\n",
            "The website will be eaten by The students.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. å‡ç´šç‰ˆè³‡æ–™åº«ï¼šåŠ å…¥åˆ†é¡æ¨™ç±¤ (Category)\n",
        "# ==========================================\n",
        "\n",
        "# å…‡æ‰‹ (Agent) - é€™äº›é€šå¸¸æ˜¯äººï¼Œå‹•ä½œæ¯”è¼ƒé€šç”¨ï¼Œæš«æ™‚ä¸éœ€åš´æ ¼é™åˆ¶\n",
        "AGENTS = [\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    {\"word\": \"I\", \"person\": 1, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"The chef\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"}, # å»šå¸«\n",
        "    {\"word\": \"The writer\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"} # ä½œå®¶\n",
        "]\n",
        "\n",
        "# å‹•è© (Verbs) - åŠ å…¥ target_req (å°å—è©çš„è¦æ±‚)\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\", \"target_req\": \"text\"},   # å¯« -> éœ€è¦æ–‡å­—é¡\n",
        "    {\"base\": \"read\", \"vpp\": \"read\", \"target_req\": \"text\"},       # è®€ -> éœ€è¦æ–‡å­—é¡\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\", \"target_req\": \"food\"},       # åƒ -> éœ€è¦é£Ÿç‰©é¡\n",
        "    {\"base\": \"cook\", \"vpp\": \"cooked\", \"target_req\": \"food\"},     # ç…® -> éœ€è¦é£Ÿç‰©é¡\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\", \"target_req\": \"project\"}, # è¨­è¨ˆ -> éœ€è¦å°ˆæ¡ˆé¡\n",
        "    {\"base\": \"build\", \"vpp\": \"built\", \"target_req\": \"project\"},     # å»ºé€  -> éœ€è¦å°ˆæ¡ˆé¡\n",
        "]\n",
        "\n",
        "# å—è© (Targets/New Subjects) - åŠ å…¥ category (åˆ†é¡)\n",
        "TARGETS = [\n",
        "    # Text é¡\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\", \"category\": \"text\"},\n",
        "    {\"word\": \"the email\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    # Food é¡\n",
        "    {\"word\": \"the apple\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    {\"word\": \"the cookies\", \"person\": 3, \"number\": \"plural\", \"category\": \"food\"},\n",
        "    {\"word\": \"the steak\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    # Project é¡\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"},\n",
        "    {\"word\": \"the bridge\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"}\n",
        "]\n",
        "\n",
        "# ä»£åè©è½‰æ›è¡¨\n",
        "PRONOUN_OBJ_MAP = {\"I\": \"me\", \"He\": \"him\", \"She\": \"her\", \"We\": \"us\", \"They\": \"them\", \"You\": \"you\"}\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ ¸å¿ƒé‚è¼¯ï¼šåŠ å…¥éæ¿¾æ©Ÿåˆ¶\n",
        "# ==========================================\n",
        "\n",
        "def get_be_verb(subject_props, tense):\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "    if tense == \"past\":\n",
        "        if number == \"singular\" and person in [1, 3]: return \"was\"\n",
        "        return \"were\"\n",
        "    elif tense == \"present\":\n",
        "        if person == 1 and number == \"singular\": return \"am\"\n",
        "        if person == 3 and number == \"singular\": return \"is\"\n",
        "        return \"are\"\n",
        "    return \"is\"\n",
        "\n",
        "def generate_smart_passive_sentence(tense=\"past\"):\n",
        "    # Step 1: å…ˆé¸å‹•è© (æ±ºå®šæƒ…å¢ƒ)\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    required_category = verb_obj[\"target_req\"]\n",
        "\n",
        "    # Step 2: *** éæ¿¾å—è© (é—œéµæ­¥é©Ÿ) ***\n",
        "    # åªå¾ TARGETS è£¡é¢æŒ‘é¸ category ç¬¦åˆçš„å­—\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == required_category]\n",
        "\n",
        "    if not valid_targets:\n",
        "        return f\"[Error: No target found for category '{required_category}']\"\n",
        "\n",
        "    target = random.choice(valid_targets)\n",
        "\n",
        "    # Step 3: é¸å…‡æ‰‹ (Agent)\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # Step 4: çµ„è£å¥å­ (è·Ÿä¹‹å‰ä¸€æ¨£)\n",
        "    # è™•ç†æ–°ä¸»è©\n",
        "    new_subject_text = target[\"word\"].capitalize()\n",
        "\n",
        "    # è™•ç† Be å‹•è© (é…åˆæ–°ä¸»è©)\n",
        "    be_verb = get_be_verb(target, tense)\n",
        "    main_verb_pp = verb_obj[\"vpp\"]\n",
        "\n",
        "    # è™•ç† By + Agent\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent.get(\"type\") == \"pronoun\":\n",
        "        agent_text = PRONOUN_OBJ_MAP.get(agent_text, agent_text)\n",
        "\n",
        "    return f\"{new_subject_text} {be_verb} {main_verb_pp} by {agent_text}.\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. é©—è­‰çµæœ\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- æ™ºæ…§è¢«å‹•èªæ…‹ (Logic Checked) ---\")\n",
        "for _ in range(8):\n",
        "    print(generate_smart_passive_sentence(tense=\"past\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0tyauaE7iBb",
        "outputId": "e9220493-2f85-4033-da6b-00c566a76c63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- æ™ºæ…§è¢«å‹•èªæ…‹ (Logic Checked) ---\n",
            "The cookies were eaten by him.\n",
            "The email was read by him.\n",
            "The bridge was designed by him.\n",
            "The apple was cooked by The students.\n",
            "The email was written by him.\n",
            "The steak was eaten by The students.\n",
            "The bridge was built by The writer.\n",
            "The book was written by me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 0. æ²¿ç”¨ä¸Šä¸€è¼ªçš„ã€Œé‚è¼¯è³‡æ–™åº«ã€\n",
        "# ==========================================\n",
        "# ç‚ºäº†ç¨‹å¼ç¢¼ç¨ç«‹æ€§ï¼Œé€™è£¡å†æ¬¡å®šç¾©è³‡æ–™ (å«åˆ†é¡æ¨™ç±¤)\n",
        "\n",
        "AGENTS = [\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"type\": \"pronoun\"},\n",
        "]\n",
        "\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\", \"target_req\": \"text\"},\n",
        "    {\"base\": \"read\", \"vpp\": \"read\", \"target_req\": \"text\"},\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\", \"target_req\": \"food\"},\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\", \"target_req\": \"project\"},\n",
        "]\n",
        "\n",
        "TARGETS = [\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\", \"category\": \"text\"},\n",
        "    {\"word\": \"the steak\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"},\n",
        "]\n",
        "\n",
        "PRONOUN_OBJ_MAP = {\"I\": \"me\", \"He\": \"him\", \"She\": \"her\", \"We\": \"us\", \"They\": \"them\", \"You\": \"you\"}\n",
        "\n",
        "# ==========================================\n",
        "# 1. æ ¸å¿ƒå·¥å…·ï¼šåŠ©å‹•è©é¸æ“‡å™¨ (Do-Support)\n",
        "# ==========================================\n",
        "def get_do_aux(subject_props, tense):\n",
        "    \"\"\"\n",
        "    æ±ºå®šè¦ç”¨ Do, Does, é‚„æ˜¯ Did\n",
        "    \"\"\"\n",
        "    if tense == \"past\":\n",
        "        return \"Did\"\n",
        "\n",
        "    # Present Tense logic\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "\n",
        "    if person == 3 and number == \"singular\":\n",
        "        return \"Does\"\n",
        "    return \"Do\"\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ ¸å¿ƒå·¥å…·ï¼šBe å‹•è©é¸æ“‡å™¨ (For Passive)\n",
        "# ==========================================\n",
        "def get_be_verb(subject_props, tense):\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "    if tense == \"past\":\n",
        "        if number == \"singular\" and person in [1, 3]: return \"Was\" # æ³¨æ„é¦–å­—å¤§å¯«\n",
        "        return \"Were\"\n",
        "    elif tense == \"present\":\n",
        "        if person == 1 and number == \"singular\": return \"Am\"\n",
        "        if person == 3 and number == \"singular\": return \"Is\"\n",
        "        return \"Are\"\n",
        "    return \"Is\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ¨¡å¼ A: ä¸»å‹•ç–‘å•å¥ç”Ÿæˆ (Active Question)\n",
        "# çµæ§‹: [Do/Does/Did] + [Subj] + [Verb Base] + [Obj]?\n",
        "# ==========================================\n",
        "def generate_active_question(tense=\"past\"):\n",
        "    # 1. é¸å‹•è© & æ ¹æ“šèªæ„é¸å—è©\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    required_category = verb_obj[\"target_req\"]\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == required_category]\n",
        "    target = random.choice(valid_targets)\n",
        "\n",
        "    # 2. é¸ä¸»è©\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # 3. *** é—œéµé‚è¼¯ï¼šé¸åŠ©å‹•è© ***\n",
        "    aux = get_do_aux(agent, tense)\n",
        "\n",
        "    # 4. è™•ç†å¤§å°å¯«èˆ‡æ ¼å¼\n",
        "    # ä¸»è©å¦‚æœä¸æ˜¯ä»£åè©(He/They)ï¼Œæ”¾ä¸­é–“è¦è®Šå°å¯« (The teacher -> the teacher)\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent[\"type\"] == \"noun\":\n",
        "        agent_text = agent_text.lower()\n",
        "    else:\n",
        "        # ä»£åè©å¦‚ He, They æ”¾ä¸­é–“è¦è®Šå°å¯« (é™¤éæ˜¯ I)\n",
        "        agent_text = agent_text.lower()\n",
        "\n",
        "    # 5. *** é—œéµé‚è¼¯ï¼šå‹•è©å¿…é ˆç”¨åŸå‹ (Base Form) ***\n",
        "    # å› ç‚ºå‰é¢æœ‰ Do/Did äº†ï¼Œå¾Œé¢å‹•è©ä¸€å¾‹ä¸è®ŠåŒ–\n",
        "    main_verb = verb_obj[\"base\"]\n",
        "\n",
        "    return f\"{aux} {agent_text} {main_verb} {target['word']}?\"\n",
        "\n",
        "# ==========================================\n",
        "# 4. æ¨¡å¼ B: è¢«å‹•ç–‘å•å¥ç”Ÿæˆ (Passive Question)\n",
        "# çµæ§‹: [Be] + [New Subj] + [Vpp] + [by Agent]?\n",
        "# ==========================================\n",
        "def generate_passive_question(tense=\"past\"):\n",
        "    # 1. ä¹Ÿæ˜¯å…ˆé¸å­— (é‚è¼¯åŒä¸Š)\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    required_category = verb_obj[\"target_req\"]\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == required_category]\n",
        "    target = random.choice(valid_targets) # é€™æ˜¯æ–°ä¸»è©\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # 2. *** é—œéµé‚è¼¯ï¼šé¸ Be å‹•è© (ç§»è‡³å¥é¦–) ***\n",
        "    # Be å‹•è©è¦çœ‹ã€Œæ–°ä¸»è© (target)ã€çš„è‡‰è‰²\n",
        "    be_verb = get_be_verb(target, tense)\n",
        "\n",
        "    # 3. è™•ç†ä¸­é–“çš„åè© (è®Šå°å¯«)\n",
        "    # é€™è£¡çš„ target æ˜¯æ™®é€šåè© (the book)ï¼Œè¦è®Šå°å¯«\n",
        "    target_text = target[\"word\"].lower() # å…¶å¯¦åŸæœ¬å°±æ˜¯å°å¯«ï¼Œä½†ä¿éšªèµ·è¦‹\n",
        "\n",
        "    # 4. è™•ç† by Agent\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent.get(\"type\") == \"pronoun\":\n",
        "        agent_text = PRONOUN_OBJ_MAP.get(agent_text, agent_text)\n",
        "\n",
        "    return f\"{be_verb} {target_text} {verb_obj['vpp']} by {agent_text}?\"\n",
        "\n",
        "# ==========================================\n",
        "# 5. é©—è­‰çµæœ\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- ä¸»å‹•ç–‘å•å¥ (Active Questions) ---\")\n",
        "print(\"[Logic: Did/Does + Subj + Base Verb]\")\n",
        "for _ in range(4):\n",
        "    print(generate_active_question(tense=\"past\")) # éå»å¼\n",
        "    print(generate_active_question(tense=\"present\")) # ç¾åœ¨å¼\n",
        "\n",
        "print(\"\\n--- è¢«å‹•ç–‘å•å¥ (Passive Questions) ---\")\n",
        "print(\"[Logic: Was/Is + Subj + Vpp]\")\n",
        "for _ in range(4):\n",
        "    print(generate_passive_question(tense=\"past\"))\n",
        "    print(generate_passive_question(tense=\"present\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QuK9AnB75G2",
        "outputId": "1e6533b4-6f77-4337-c5c2-4dc7ea2d3954"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ä¸»å‹•ç–‘å•å¥ (Active Questions) ---\n",
            "[Logic: Did/Does + Subj + Base Verb]\n",
            "Did he design the website?\n",
            "Does he design the website?\n",
            "Did he design the website?\n",
            "Do they eat the steak?\n",
            "Did the teacher write the letters?\n",
            "Do the students read the letters?\n",
            "Did the teacher read the book?\n",
            "Does the teacher write the book?\n",
            "\n",
            "--- è¢«å‹•ç–‘å•å¥ (Passive Questions) ---\n",
            "[Logic: Was/Is + Subj + Vpp]\n",
            "Were the letters read by The students?\n",
            "Is the steak eaten by The students?\n",
            "Were the letters written by The students?\n",
            "Are the letters written by them?\n",
            "Was the book written by The students?\n",
            "Are the letters read by them?\n",
            "Was the steak eaten by The teacher?\n",
            "Are the letters written by him?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. è³‡æ–™åº« (ç¨å¾®æ“´å……ä»¥æ¸¬è©¦å°ˆæœ‰åè©)\n",
        "# ==========================================\n",
        "AGENTS = [\n",
        "    # æ™®é€šåè© (éœ€è¦è®Šå°å¯«)\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    # ä»£åè© (éœ€è¦è®Šå—æ ¼æˆ–å°å¯«)\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"type\": \"pronoun\"},\n",
        "    # å°ˆæœ‰åè© (æ°¸é å¤§å¯«ï¼Œæ¸¬è©¦ç”¨)\n",
        "    {\"word\": \"John\", \"person\": 3, \"number\": \"singular\", \"type\": \"proper_noun\"},\n",
        "]\n",
        "\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\", \"target_req\": \"text\"},\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\", \"target_req\": \"food\"},\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\", \"target_req\": \"project\"},\n",
        "]\n",
        "\n",
        "TARGETS = [\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\", \"category\": \"text\"},\n",
        "    {\"word\": \"the steak\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"},\n",
        "]\n",
        "\n",
        "PRONOUN_OBJ_MAP = {\"I\": \"me\", \"He\": \"him\", \"She\": \"her\", \"We\": \"us\", \"They\": \"them\", \"You\": \"you\"}\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ ¸å¿ƒå·¥å…·ï¼šæ ¼å¼åŒ–å¤§å¸« (New!)\n",
        "# ==========================================\n",
        "def format_mid_sentence(word_obj, case_type=\"subject\"):\n",
        "    \"\"\"\n",
        "    word_obj: è³‡æ–™åº«è£¡é‚£ä¸€æ•´åŒ… (åŒ…å« word, type)\n",
        "    case_type: \"subject\" (ä¸»æ ¼, ex: Did he...) æˆ– \"object\" (å—æ ¼, ex: by him)\n",
        "    \"\"\"\n",
        "    text = word_obj[\"word\"]\n",
        "    w_type = word_obj.get(\"type\", \"noun\")\n",
        "\n",
        "    # --- ç‹€æ³ A: å®ƒæ˜¯ä»£åè© (He, They, I) ---\n",
        "    if w_type == \"pronoun\":\n",
        "        if case_type == \"object\":\n",
        "            # è½‰å—æ ¼ (He -> him, They -> them)\n",
        "            # å—æ ¼é€šå¸¸å·²ç¶“æ˜¯å°å¯«äº† (him, them, me)\n",
        "            return PRONOUN_OBJ_MAP.get(text, text)\n",
        "        else:\n",
        "            # ç¶­æŒä¸»æ ¼ä½†è®Šå°å¯« (Did he...?)\n",
        "            # ä¾‹å¤–ï¼š \"I\" æ°¸é å¤§å¯«\n",
        "            if text == \"I\":\n",
        "                return \"I\"\n",
        "            return text.lower() # He -> he\n",
        "\n",
        "    # --- ç‹€æ³ B: å®ƒæ˜¯æ™®é€šåè© (The teacher) ---\n",
        "    elif w_type == \"noun\":\n",
        "        # å¼·åˆ¶è½‰å°å¯« (The teacher -> the teacher)\n",
        "        return text.lower()\n",
        "\n",
        "    # --- ç‹€æ³ C: å®ƒæ˜¯å°ˆæœ‰åè© (John, Taiwan) ---\n",
        "    elif w_type == \"proper_noun\":\n",
        "        # ä¿æŒåŸæ¨£ï¼Œä¸å‹• (John -> John)\n",
        "        return text\n",
        "\n",
        "    return text\n",
        "\n",
        "# ==========================================\n",
        "# 3. è¼”åŠ©å‡½å¼ (æ²¿ç”¨)\n",
        "# ==========================================\n",
        "def get_be_verb(subject_props, tense):\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "    if tense == \"past\":\n",
        "        if number == \"singular\" and person in [1, 3]: return \"Was\"\n",
        "        return \"Were\"\n",
        "    elif tense == \"present\":\n",
        "        if person == 1 and number == \"singular\": return \"Am\"\n",
        "        if person == 3 and number == \"singular\": return \"Is\"\n",
        "        return \"Are\"\n",
        "    return \"Is\"\n",
        "\n",
        "def get_do_aux(subject_props, tense):\n",
        "    if tense == \"past\": return \"Did\"\n",
        "    person = subject_props[\"person\"]\n",
        "    number = subject_props[\"number\"]\n",
        "    if person == 3 and number == \"singular\": return \"Does\"\n",
        "    return \"Do\"\n",
        "\n",
        "# ==========================================\n",
        "# 4. ç”Ÿæˆé‚è¼¯ï¼šå¥—ç”¨æ ¼å¼åŒ–å·¥å…·\n",
        "# ==========================================\n",
        "\n",
        "def generate_passive_question_v2(tense=\"past\"):\n",
        "    # é¸å­—\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    req = verb_obj[\"target_req\"]\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == req]\n",
        "    target = random.choice(valid_targets)\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # çµ„åˆ\n",
        "    be_verb = get_be_verb(target, tense)\n",
        "\n",
        "    # target æ”¾åœ¨ä¸­é–“ï¼Œè¦è®Šå°å¯« (The book -> the book)\n",
        "    target_text = target[\"word\"].lower()\n",
        "\n",
        "    # *** ä¿®æ­£é»ï¼šä½¿ç”¨ format_mid_sentence è™•ç† Agent ***\n",
        "    # é€™è£¡æ˜¯ by + Agentï¼Œæ‰€ä»¥æ˜¯ç”¨ \"object\" (å—æ ¼) æ¨¡å¼\n",
        "    agent_text = format_mid_sentence(agent, case_type=\"object\")\n",
        "\n",
        "    return f\"{be_verb} {target_text} {verb_obj['vpp']} by {agent_text}?\"\n",
        "\n",
        "def generate_active_question_v2(tense=\"past\"):\n",
        "    # é¸å­—\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    req = verb_obj[\"target_req\"]\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == req]\n",
        "    target = random.choice(valid_targets)\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # çµ„åˆ\n",
        "    aux = get_do_aux(agent, tense)\n",
        "\n",
        "    # *** ä¿®æ­£é»ï¼šä½¿ç”¨ format_mid_sentence è™•ç† Agent ***\n",
        "    # é€™è£¡æ˜¯ Did + Agentï¼Œæ‰€ä»¥æ˜¯ç”¨ \"subject\" (ä¸»æ ¼) æ¨¡å¼\n",
        "    agent_text = format_mid_sentence(agent, case_type=\"subject\")\n",
        "\n",
        "    main_verb = verb_obj[\"base\"]\n",
        "\n",
        "    return f\"{aux} {agent_text} {main_verb} {target['word']}?\"\n",
        "\n",
        "# ==========================================\n",
        "# 5. é©—è­‰æ™‚åˆ»\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- ä¿®æ­£ç‰ˆï¼šè¢«å‹•ç–‘å•å¥ (Passive Question) ---\")\n",
        "for _ in range(5):\n",
        "    print(generate_passive_question_v2(tense=\"past\"))\n",
        "\n",
        "print(\"\\n--- ä¿®æ­£ç‰ˆï¼šä¸»å‹•ç–‘å•å¥ (Active Question) ---\")\n",
        "for _ in range(5):\n",
        "    print(generate_active_question_v2(tense=\"past\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyA7B43Y8Q4X",
        "outputId": "bc3b0cc2-6972-44ec-fcb9-70fcfa4df200"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ä¿®æ­£ç‰ˆï¼šè¢«å‹•ç–‘å•å¥ (Passive Question) ---\n",
            "Was the website designed by the teacher?\n",
            "Were the letters written by the teacher?\n",
            "Was the website designed by the teacher?\n",
            "Was the book written by the students?\n",
            "Was the book written by John?\n",
            "\n",
            "--- ä¿®æ­£ç‰ˆï¼šä¸»å‹•ç–‘å•å¥ (Active Question) ---\n",
            "Did he design the website?\n",
            "Did they write the letters?\n",
            "Did he eat the steak?\n",
            "Did John design the website?\n",
            "Did he design the website?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import lemminflect # é€™æ˜¯ç”ŸæˆéŒ¯èª¤é¸é …çš„ç¥å™¨\n",
        "\n",
        "# ==========================================\n",
        "# 0. è³‡æ–™åº«æº–å‚™ (æ²¿ç”¨ä¸Šä¸€è¼ª)\n",
        "# ==========================================\n",
        "AGENTS = [\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"type\": \"pronoun\"},\n",
        "]\n",
        "\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\", \"target_req\": \"text\"},\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\", \"target_req\": \"food\"},\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\", \"target_req\": \"project\"},\n",
        "    {\"base\": \"buy\", \"vpp\": \"bought\", \"target_req\": \"food\"}, # æ–°å¢\n",
        "]\n",
        "\n",
        "TARGETS = [\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\", \"category\": \"text\"},\n",
        "    {\"word\": \"the steak\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"},\n",
        "]\n",
        "\n",
        "PRONOUN_OBJ_MAP = {\"I\": \"me\", \"He\": \"him\", \"She\": \"her\", \"We\": \"us\", \"They\": \"them\", \"You\": \"you\"}\n",
        "\n",
        "# ==========================================\n",
        "# 1. æ ¸å¿ƒå·¥å…·ï¼šå¹²æ“¾é …ç”Ÿæˆå™¨ (Distractor Generator)\n",
        "# ==========================================\n",
        "def generate_verb_options(base_word, correct_form):\n",
        "    \"\"\"\n",
        "    è¼¸å…¥: base='eat', correct='ate'\n",
        "    è¼¸å‡º: ['eat', 'eaten', 'eating', 'ate'] (æ‰“äº‚é †åº)\n",
        "    \"\"\"\n",
        "    options = set()\n",
        "    options.add(correct_form) # æ­£è§£\n",
        "\n",
        "    # åˆ©ç”¨ lemminflect ç”¢ç”Ÿå…¶ä»–è®ŠåŒ–å½¢ç•¶ä½œèª˜ç­”\n",
        "    options.add(base_word) # åŸå‹ (eat)\n",
        "    options.add(lemminflect.getInflection(base_word, tag='VBG')[0]) # ç¾åœ¨åˆ†è© (eating)\n",
        "    options.add(lemminflect.getInflection(base_word, tag='VBN')[0]) # éå»åˆ†è© (eaten)\n",
        "\n",
        "    # ç‚ºäº†æ¹Šæ»¿4å€‹ï¼Œå¦‚æœé‡è¤‡äº†(ä¾‹å¦‚ put/put/put)ï¼Œå°±éš¨æ©ŸåŠ  s\n",
        "    if len(options) < 4:\n",
        "        options.add(lemminflect.getInflection(base_word, tag='VBZ')[0]) # ç¬¬ä¸‰äººç¨± (eats)\n",
        "\n",
        "    final_list = list(options)\n",
        "    random.shuffle(final_list)\n",
        "    return final_list\n",
        "\n",
        "# ==========================================\n",
        "# 2. æ¨¡å¼ A: æ™‚æ…‹å¡«ç©º (Tense Cloze)\n",
        "# é¡Œç›®: He ____ (eat) the steak.\n",
        "# ==========================================\n",
        "def generate_tense_cloze():\n",
        "    # 1. é¸æ\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    req = verb_obj[\"target_req\"]\n",
        "    target = random.choice([t for t in TARGETS if t[\"category\"] == req])\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # 2. æ±ºå®šæ­£ç¢ºç­”æ¡ˆ (å‡è¨­æˆ‘å€‘è€ƒéå»å¼)\n",
        "    tense = \"past\"\n",
        "    correct_verb = lemminflect.getInflection(verb_obj[\"base\"], tag='VBD')[0]\n",
        "\n",
        "    # 3. *** æŒ–ç©ºè™•ç† ***\n",
        "    # æˆ‘å€‘ä¸ç›´æ¥æ”¾ correct_verbï¼Œè€Œæ˜¯æ”¾ \"____ (base)\"\n",
        "    question_part = f\"____ ({verb_obj['base']})\"\n",
        "\n",
        "    # 4. çµ„è£é¡Œç›®å­—ä¸²\n",
        "    # è™•ç†ä¸»è©æ ¼å¼\n",
        "    subj_text = agent[\"word\"] # He / The teacher\n",
        "\n",
        "    sentence = f\"{subj_text} {question_part} {target['word']}.\"\n",
        "\n",
        "    # 5. ç”Ÿæˆé¸é …\n",
        "    options = generate_verb_options(verb_obj[\"base\"], correct_verb)\n",
        "\n",
        "    return {\n",
        "        \"type\": \"Simple Past Tense\",\n",
        "        \"question\": sentence,\n",
        "        \"answer\": correct_verb,\n",
        "        \"options\": options\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# 3. æ¨¡å¼ B: è¢«å‹•èªæ…‹ Be å‹•è©å¡«ç©º (Passive Be Cloze)\n",
        "# é¡Œç›®: The letters ____ written by him. (è€ƒå–®è¤‡æ•¸èˆ‡æ™‚æ…‹)\n",
        "# ==========================================\n",
        "def generate_passive_be_cloze():\n",
        "    # 1. é¸æ\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "    target = random.choice([t for t in TARGETS if t[\"category\"] == verb_obj[\"target_req\"]])\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # 2. æ±ºå®šæ­£ç¢ºç­”æ¡ˆ (å‡è¨­è€ƒéå»å¼)\n",
        "    tense = \"past\"\n",
        "\n",
        "    # åˆ¤æ–· Be å‹•è© (ä¾æ“š Target çš„å–®è¤‡æ•¸)\n",
        "    person, number = target[\"person\"], target[\"number\"]\n",
        "    if number == \"singular\":\n",
        "        correct_be = \"was\"\n",
        "        distractor_be = \"were\"\n",
        "    else:\n",
        "        correct_be = \"were\"\n",
        "        distractor_be = \"was\"\n",
        "\n",
        "    # 3. *** æŒ–ç©ºè™•ç† ***\n",
        "    # é€™æ¬¡æç¤ºæ¯”è¼ƒå°‘ï¼Œè€ƒé©—æ–‡æ³•è§€å¿µ\n",
        "    question_part = \"____\"\n",
        "\n",
        "    # 4. çµ„è£\n",
        "    target_text = target[\"word\"].capitalize() # å¥é¦–å¤§å¯«\n",
        "\n",
        "    # è™•ç† Agent (by + å—æ ¼)\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent[\"type\"] == \"pronoun\":\n",
        "        agent_text = PRONOUN_OBJ_MAP.get(agent_text, agent_text)\n",
        "\n",
        "    sentence = f\"{target_text} {question_part} {verb_obj['vpp']} by {agent_text}.\"\n",
        "\n",
        "    # 5. ç”Ÿæˆé¸é … (æ··æ·†è¦–è½)\n",
        "    options = [correct_be, distractor_be, \"is\", \"are\"]\n",
        "    random.shuffle(options)\n",
        "\n",
        "    return {\n",
        "        \"type\": \"Passive Voice (Be-Verb Agreement)\",\n",
        "        \"question\": sentence,\n",
        "        \"answer\": correct_be,\n",
        "        \"options\": options\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# 4. é©—è­‰èˆ‡å±•ç¤º\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- é¡Œçµ„ 1: éå»å¼å‹•è©ç·´ç¿’ (Verb Tense) ---\")\n",
        "for i in range(1, 4):\n",
        "    q = generate_tense_cloze()\n",
        "    print(f\"Q{i}: {q['question']}\")\n",
        "    print(f\"    [é¸é …]: {q['options']}\")\n",
        "    print(f\"    [è§£ç­”]: {q['answer']}\\n\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"--- é¡Œçµ„ 2: è¢«å‹•èªæ…‹ Be å‹•è©ç·´ç¿’ (Passive Agreement) ---\")\n",
        "for i in range(1, 4):\n",
        "    q = generate_passive_be_cloze()\n",
        "    print(f\"Q{i}: {q['question']}\")\n",
        "    print(f\"    [é¸é …]: {q['options']}\")\n",
        "    print(f\"    [è§£ç­”]: {q['answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa9VlvhU8kHp",
        "outputId": "3c273594-2afa-44d4-e666-051a377c5fa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- é¡Œçµ„ 1: éå»å¼å‹•è©ç·´ç¿’ (Verb Tense) ---\n",
            "Q1: He ____ (buy) the steak.\n",
            "    [é¸é …]: ['bought', 'buying', 'buy', 'buys']\n",
            "    [è§£ç­”]: bought\n",
            "\n",
            "Q2: He ____ (buy) the steak.\n",
            "    [é¸é …]: ['buys', 'buying', 'buy', 'bought']\n",
            "    [è§£ç­”]: bought\n",
            "\n",
            "Q3: He ____ (design) the website.\n",
            "    [é¸é …]: ['design', 'designed', 'designing', 'designs']\n",
            "    [è§£ç­”]: designed\n",
            "\n",
            "----------------------------------------\n",
            "--- é¡Œçµ„ 2: è¢«å‹•èªæ…‹ Be å‹•è©ç·´ç¿’ (Passive Agreement) ---\n",
            "Q1: The book ____ written by him.\n",
            "    [é¸é …]: ['is', 'are', 'was', 'were']\n",
            "    [è§£ç­”]: was\n",
            "\n",
            "Q2: The steak ____ bought by them.\n",
            "    [é¸é …]: ['were', 'are', 'was', 'is']\n",
            "    [è§£ç­”]: was\n",
            "\n",
            "Q3: The book ____ written by The students.\n",
            "    [é¸é …]: ['was', 'are', 'were', 'is']\n",
            "    [è§£ç­”]: was\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 0. åŸºç¤è³‡æ–™åº« (æ²¿ç”¨)\n",
        "# ==========================================\n",
        "AGENTS = [\n",
        "    {\"word\": \"The teacher\", \"person\": 3, \"number\": \"singular\", \"type\": \"noun\"},\n",
        "    {\"word\": \"The students\", \"person\": 3, \"number\": \"plural\", \"type\": \"noun\"},\n",
        "    {\"word\": \"He\", \"person\": 3, \"number\": \"singular\", \"type\": \"pronoun\"},\n",
        "    {\"word\": \"They\", \"person\": 3, \"number\": \"plural\", \"type\": \"pronoun\"},\n",
        "]\n",
        "\n",
        "TRANSITIVE_VERBS = [\n",
        "    {\"base\": \"write\", \"vpp\": \"written\", \"target_req\": \"text\"},\n",
        "    {\"base\": \"eat\", \"vpp\": \"eaten\", \"target_req\": \"food\"},\n",
        "    {\"base\": \"design\", \"vpp\": \"designed\", \"target_req\": \"project\"},\n",
        "    {\"base\": \"buy\", \"vpp\": \"bought\", \"target_req\": \"food\"},\n",
        "    {\"base\": \"clean\", \"vpp\": \"cleaned\", \"target_req\": \"place\"}, # æ–°å¢\n",
        "]\n",
        "\n",
        "TARGETS = [\n",
        "    {\"word\": \"the book\", \"person\": 3, \"number\": \"singular\", \"category\": \"text\"},\n",
        "    {\"word\": \"the letters\", \"person\": 3, \"number\": \"plural\", \"category\": \"text\"},\n",
        "    {\"word\": \"the steak\", \"person\": 3, \"number\": \"singular\", \"category\": \"food\"},\n",
        "    {\"word\": \"the room\", \"person\": 3, \"number\": \"singular\", \"category\": \"place\"},\n",
        "    {\"word\": \"the website\", \"person\": 3, \"number\": \"singular\", \"category\": \"project\"}, # æ–°å¢ 'project' é¡åˆ¥çš„ç›®æ¨™\n",
        "]\n",
        "\n",
        "PRONOUN_OBJ_MAP = {\"I\": \"me\", \"He\": \"him\", \"She\": \"her\", \"We\": \"us\", \"They\": \"them\", \"You\": \"you\"}\n",
        "\n",
        "# ==========================================\n",
        "# 1. æ–°å¢ï¼šæ™‚é–“å‰¯è©åº« (Time Anchors)\n",
        "# ==========================================\n",
        "TIME_MARKERS = {\n",
        "    \"past\": [\n",
        "        \"yesterday\", \"last night\", \"two days ago\", \"last week\", \"in 2020\"\n",
        "    ],\n",
        "    \"present\": [\n",
        "        \"every day\", \"usually\", \"on Sundays\", \"every week\", \"always\"\n",
        "    ],\n",
        "    # æœªä¾†å¼æš«ä¸ä½¿ç”¨ï¼Œå› ç‚ºè¢«å‹•èªæ…‹æœªä¾†å¼çµæ§‹ä¸åŒ (will be)\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. å‡ç´šç‰ˆï¼šå¸¶æ™‚é–“é™åˆ¶çš„å¡«ç©ºé¡Œ\n",
        "# ==========================================\n",
        "def generate_passive_be_cloze_with_time():\n",
        "    # 1. é¸æ\n",
        "    verb_obj = random.choice(TRANSITIVE_VERBS)\n",
        "\n",
        "    # ä¿®æ­£é»ï¼šåœ¨é¸æ“‡ target ä¹‹å‰ï¼Œå…ˆæª¢æŸ¥ valid_targets æ˜¯å¦ç‚ºç©º\n",
        "    valid_targets = [t for t in TARGETS if t[\"category\"] == verb_obj[\"target_req\"]]\n",
        "\n",
        "    if not valid_targets:\n",
        "        # å¦‚æœæ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„å—è©ï¼Œè¿”å›ä¸€å€‹éŒ¯èª¤è¨Šæ¯è€Œä¸æ˜¯å´©æ½°\n",
        "        return {\n",
        "            \"type\": \"Error\",\n",
        "            \"question\": f\"Error: No matching target found for verb category '{verb_obj['target_req']}'\",\n",
        "            \"answer\": \"N/A\",\n",
        "            \"options\": []\n",
        "        }\n",
        "\n",
        "    target = random.choice(valid_targets)\n",
        "    agent = random.choice(AGENTS)\n",
        "\n",
        "    # 2. *** éš¨æ©Ÿæ±ºå®šæ™‚æ…‹ (Past or Present) ***\n",
        "    tense = random.choice([\"past\", \"present\"])\n",
        "\n",
        "    # 3. æ ¹æ“šæ™‚æ…‹é¸æ“‡ Be å‹•è© (æ­£ç¢ºç­”æ¡ˆ)\n",
        "    person, number = target[\"person\"], target[\"number\"]\n",
        "\n",
        "    if tense == \"past\":\n",
        "        if number == \"singular\": correct_be = \"was\"\n",
        "        else: correct_be = \"were\"\n",
        "    else: # present\n",
        "        if number == \"singular\": correct_be = \"is\"\n",
        "        else: correct_be = \"are\"\n",
        "\n",
        "    # 4. *** é—œéµï¼šé¸å–å°æ‡‰çš„æ™‚é–“è© ***\n",
        "    time_marker = random.choice(TIME_MARKERS[tense])\n",
        "\n",
        "    # 5. çµ„è£é¡Œç›®\n",
        "    target_text = target[\"word\"].capitalize()\n",
        "\n",
        "    agent_text = agent[\"word\"]\n",
        "    if agent[\"type\"] == \"pronoun\":\n",
        "        agent_text = PRONOUN_OBJ_MAP.get(agent_text, agent_text)\n",
        "\n",
        "    # æ ¼å¼: [Target] ____ [Vpp] by [Agent] [Time].\n",
        "    sentence = f\"{target_text} ____ {verb_obj['vpp']} by {agent_text} {time_marker}.\"\n",
        "\n",
        "    # 6. ç”Ÿæˆé¸é … (ä¸€å®šè¦åŒ…å«æ··æ·†è¦–è½çš„éŒ¯èª¤æ™‚æ…‹)\n",
        "    # æˆ‘å€‘çš„ç›®æ¨™æ˜¯ï¼šæ—¢ç„¶é¡Œç›®æœ‰ yesterdayï¼Œé¸é …è£¡ä¸€å®šè¦æœ‰ is/are ä¾†è®“å­¸ç”Ÿé¸éŒ¯\n",
        "    distractors = set()\n",
        "\n",
        "    # åŠ å…¥éŒ¯èª¤çš„æ•¸ (Wrong Number)\n",
        "    if correct_be == \"was\": distractors.add(\"were\")\n",
        "    if correct_be == \"were\": distractors.add(\"was\")\n",
        "    if correct_be == \"is\": distractors.add(\"are\")\n",
        "    if correct_be == \"are\": distractors.add(\"is\")\n",
        "\n",
        "    # åŠ å…¥éŒ¯èª¤çš„æ™‚æ…‹ (Wrong Tense) - é€™æ˜¯æœ€é‡è¦çš„å¹²æ“¾é …ï¼\n",
        "    if tense == \"past\":\n",
        "        distractors.add(\"is\")\n",
        "        distractors.add(\"are\")\n",
        "    else:\n",
        "        distractors.add(\"was\")\n",
        "        distractors.add(\"were\")\n",
        "\n",
        "    # è½‰æˆ list ä¸¦æ´—ç‰Œ\n",
        "    final_options = list(distractors)\n",
        "    # ç¢ºä¿åªæœ‰ 3 å€‹å¹²æ“¾é … + 1 å€‹æ­£ç¢ºç­”æ¡ˆ\n",
        "    if len(final_options) > 3:\n",
        "        final_options = final_options[:3]\n",
        "\n",
        "    final_options.append(correct_be)\n",
        "    random.shuffle(final_options)\n",
        "\n",
        "    return {\n",
        "        \"type\": f\"Passive Voice ({tense.capitalize()})\",\n",
        "        \"question\": sentence,\n",
        "        \"answer\": correct_be,\n",
        "        \"options\": final_options\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# 3. é©—è­‰çµæœ\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- åš´è¬¹ç‰ˆï¼šé™„å¸¶æ™‚é–“æç¤ºçš„å¡«ç©ºé¡Œ ---\")\n",
        "for i in range(1, 6):\n",
        "    q = generate_passive_be_cloze_with_time()\n",
        "    print(f\"Q{i}: {q['question']}\")\n",
        "    print(f\"    [é¸é …]: {q['options']}\")\n",
        "    print(f\"    [è§£ç­”]: {q['answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60NejFUE9E88",
        "outputId": "a74b3756-0808-4457-ea55-469a2ff981b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- åš´è¬¹ç‰ˆï¼šé™„å¸¶æ™‚é–“æç¤ºçš„å¡«ç©ºé¡Œ ---\n",
            "Q1: The steak ____ eaten by him last night.\n",
            "    [é¸é …]: ['is', 'was', 'are', 'were']\n",
            "    [è§£ç­”]: was\n",
            "\n",
            "Q2: Error: No matching target found for verb category 'project'\n",
            "    [é¸é …]: []\n",
            "    [è§£ç­”]: N/A\n",
            "\n",
            "Q3: The steak ____ bought by The teacher usually.\n",
            "    [é¸é …]: ['was', 'is', 'are', 'were']\n",
            "    [è§£ç­”]: is\n",
            "\n",
            "Q4: Error: No matching target found for verb category 'project'\n",
            "    [é¸é …]: []\n",
            "    [è§£ç­”]: N/A\n",
            "\n",
            "Q5: The steak ____ bought by him in 2020.\n",
            "    [é¸é …]: ['is', 'are', 'were', 'was']\n",
            "    [è§£ç­”]: was\n",
            "\n"
          ]
        }
      ]
    }
  ]
}